## **ASSESSMENT AND** **GENERATIVE ARTIFICIAL** **INTELLIGENCE IN HIGHER** **EDUCATION**

#### April 2024

In the following report, Hanover Research examines
research literature, trade publications, and case studies
highlighting emerging strategies in higher education to
account for, or even incorporate, generative artificial
intelligence when designing student assessments.


### **TABLE OF CONTENTS** 3 / Recommendations and Key Findings 4 / Introduction and Methodology 5 / Landscape Review – Generative AI In Assessment 11 / Generative AI Case Studies and Assessment Use Cases

HIGHER EDUCATION
**2**


### **EXECUTIVE SUMMARY**

**RECOMMENDATIONS**

_Based on an analysis of generative AI assessment case studies and best practices, Hanover_
_recommends that institutions:_


**AVOID RELYING ON TOOLS LIKE GPTZ** **ERO** **OR OTHER AI**
**DETECTION SERVICES, WHICH HAVE AN EXTREMELY POOR**
**ACCURACY RECORD AND MAY MAKE THE CLASSROOM**
**CLIMATE UNECSSARILY ADVERSARIAL.**


OpenAI, the maker of ChatGPT, experimented with its own AI detection
service, which achieved a success rate of just 26 percent. Experts are
similarly skeptical of other third-party vendors selling detection systems.


**REVAMP WRITING ASSIGNMENTS TO INCLUDE SCAFFOLDED**
**DELIVERABLES OVER A PERIOD OF TIME AND FOCUS ON**
**STUDENTS’ DEVELOPMENT PROCESSES.**


Writing assignments, which are the most common application for
generative AI, should be modified to include intensive, iterative instructor
feedback and revision over time. This shift to a process focus amplifies
the use of formative assessment to develop students’ skills, and
somewhat de-emphasizes the final product.


**INCORPORATE GENERATIVE AI PRODUCTS INTO STUDENTS’**
**WRITING AND ANALYSIS ASSIGNMENTS.**


Generative AI tools can be used to help students revise or critique their
own writing, to generate and compare ideas and evidence, and as writing
artifacts that allow students to contrast human writing with AI-produced
work. Learning to brainstorm and write with AI, understand its limitations
and weaknesses, and recognize its biases or blind spots are essential skills
for navigating a world where generative AI will be commonplace.



**KEY FINDINGS**


**In the year since OpenAI released ChatGPT 3.5, many of the**
**technology’s promised applications like formative assessment and**
**personalized interactive tutoring remain under-realized.** The leaders in
applying these technologies for uses beyond writing student term papers
are often technology companies, rather than colleges or universities.
Recent reviews of GPT-powered tools like Duolingo’s RolePlay and
Explain My Answer and Khan Academy’s Khanmigo suggest that they are
useful, and more interactive than earlier chatbots, but still not close to
replacing human instructors.


**Survey data from the spring 2023 semester suggest that around 30**
**percent of postsecondary students had used generative AI in their**
**schoolwork, and that 51 percent of respondents view it as a form of**
**cheating or plagiarism.** Of the subset of users that report “frequent” use
(46 percent) only eight percent believed that generative AI had improved
their grades, which may reflect the ongoing challenges these tools have
with producing sharp arguments and convincing personal narratives. The
ongoing debate among students about the ethical implications of using
generative AI likely means that faculty will find most students receptive
to conversations about academic honesty and appropriate use and
citation.


**To make assignments more generative AI-resistant, faculty are relying**
**more heavily on process-focused formative assessments in writing**
**assignments, in-class work, and group projects.** Assignments that
specifically ask students to use (and cite) generative AI resources and
then evaluate their outputs are also a highly-recommended practice. The
overall assumption among universities appears to be that these resources
are going to be ubiquitous in higher education and the workplace, and
that students must be equipped to interact with them critically and
responsibly.



HIGHER EDUCATION **3**


### **INTRODUCTION AND METHODOLOGY**

**INTRODUCTION AND METHODOLOGY**


Institutions anticipate significant shifts in the labor market, driven by the
advent of ChatGPT. These changes necessitate a fundamental rethinking
of higher education institutions’ operations, including curriculum design
and teaching methods. To better prepare for these impending changes,
Hanover summarizes emerging trends in this area.


**REPORT CONTENTS AND STRUCTURE**


**This report includes two sections:**


➢ **Section I: Landscape Review – Generative AI In Assessment** provides

an overview of generative AI and its impacts on assessment in a
postsecondary education environment. The analysis draws on
academic studies, trade publications, and news features to map out
the current state of generative AI and its impacts on, and role within,
assessment and evaluation of student progress.


➢ **Section II:** **Generative AI Case Studies and Assessment Use Cases**

looks at three university examples and one education technology
industry example of strategies for helping students to navigate the
impacts of generative AI in the workforce and the world at large. It
begins with a case study looking at AI as a tutoring and assessment
resource in subscription-only versions of the language learning app
Duolingo. The profiles of the University of Wisconsin and Montclair
State University resources on generative AI offer insight into
universities’ evolving perspective on their role preparing students to
function in a world and workplace with ubiquitous access to
generative AI. These profiles, plus the third university case study
featuring Australia’s Monash University, also provide insights into how
universities are rethinking assessment to mitigate students’
unauthorized use of AI to complete assignments.



**RESEARCH QUESTION**


**a**
**What are the emerging trends in discussions about how**
**generative artificial intelligence (AI) is changing the way**
**higher education institutions teach, particularly in**
**relation to competency-based education and**
**assessment?**


**SOURCE AND METHODOLOGY NOTE**


**Chat GPT 3.5 launched on November 30, 2022, making widespread**
**public access to Large Language Model (LLM) artificial intelligence tools**
**a very recent phenomenon.** With this in mind, institutions of higher
education, to say nothing of other industries, have been forced to adapt
very quickly and are still navigating the complexities of generative AI and
its impacts on education, commerce, and society at large. The rapid
release of other, sometimes updated, resources such as Chat GPT-4, Bing
(based on GPT-4), Dall-E 2 (which creates images), and Bard (Google)
means that strategies that were sound a year ago may no longer be so
today. Hanover expects that generative AI guides and resources
produced by higher education institutions will continue to evolve in the
coming year, and that we will also have much more insight into the
performance and limitations of newly-released generative AI-powered
tools with continued exposure. Given the novelty of the topic and the
fact that many innovations are occurring outside of higher education, we
have including non-university examples.



HIGHER EDUCATION **4**


# LANDSCAPE REVIEW – GENERATIVE AI IN ASSESSMENT

_Overview of generative AI as an assessment tool in higher education and beyond._


### **SURVEYING THE LANDSCAPE – GENERATIVE AI AND ASSESSMENT**



**HOW ARE STUDENTS USING GENERATIVE**

**AI?**


**[In a May 2023 opinion piece in](https://www.chronicle.com/article/im-a-student-you-have-no-idea-how-much-were-using-chatgpt)** _**The Chronicle of Higher Education**_ **, Owen**
**Kichizo Terry suggests that most university students do not rely**
**exclusively on Chat GPT and similar tools to write essays; instead they**
**use it to craft a framework for their argument.** His example recounts the
use of Chat GPT (most likely the free 3.5 version available at the time of
publication) to identify a debatable thesis for a six-page term paper on
_The Iliad_, and to help him come up with supporting arguments and
evidence from the text. For the most part he wrote the essay at the
sentence level, but he recounts that “all that was left now was for me to
follow these instructions, and perhaps modify the structure a bit where I
deemed the computer’s reasoning flawed or lackluster.”



_**In reality, it’s very easy**_ **A** **September** **2023** **[survey](https://www.intelligent.com/one-third-of-college-students-used-chatgpt-for-schoolwork-during-the-2022-23-academic-year/)**

**published** **by** **Intelligent.com**

_**to use AI to do the lion’s share**_

**found** **that** **30** **percent** **of**

_**of the thinking while still**_ **students had used ChatGPT for**
_**submitting work that looks like**_ **schoolwork in the previous year.**

_**your own. Once that becomes**_ Among them, 46 percent said

_**clear, it follows that massive**_ they “frequently” use the tool

_**structural change will be**_ and that English, followed by
_**needed if our colleges are going**_ hard sciences such as chemistry

_**to keep training students to**_ and biology, are the disciplines

where they are most likely to

_**think critically.**_

deploy it. Only one in twelve
chat GPA users credited the tool

_The Chronicle of Higher Education,_

_[Owen Kichizo Terry, May 2023](https://www.chronicle.com/article/im-a-student-you-have-no-idea-how-much-were-using-chatgpt)_ with raising their GPA, however.

According to a March 2023 _Best_
_Colleges_ [survey, 51 percent of college students agree that using](https://www.bestcolleges.com/research/college-students-ai-tools-survey/#:~:text=Half%20of%20College%20Students%20Say%20Using%20AI%20on%20Schoolwork%20Is,in%205%20use%20them%20anyway.)
generative AI on assignments is a form of cheating or plagiarism, but 22
percent had used the tool.



**A RANGE OF FACULTY RESPONSES**


**Responses to the rise of generative AI range from alarm to limited**
**concern and include calls to embrace the technology as a part of**
**students’ learning processes and to offer at least some forms of**
**assessment where students cannot access the technology.** On the less
reactive end of the spectrum, John Warner’s April 2023 _Inside Higher Ed_
[blog post, “ChatGPT and Writing Assessment, an Old Problem Made](https://www.insidehighered.com/opinion/blogs/just-visiting/2023/04/21/chatgpt-and-writing-assessment-old-problem-made-new)
New,” contends that generative AI writing achieves “surface-level
fluency” that requires faculty to grade more stringently for the substance
of students’ arguments. He argues that in the post-GPT world writing
assignments must be “tied to authentic occasions for learning” and
repeatedly pushing students to sharpen and deepen their arguments over
multiple drafts. As the case studies in Section II will show, this focus on
process rather than product is a common strategy.


**Meanwhile, Inara Scott’s April 2023** _**Inside Higher Ed**_ **[article sounds](https://www.insidehighered.com/opinion/views/2023/04/18/yes-we-are-chatgpt-crisis)**
**growing alarm about the pervasive use of generative AI in student work,**
**and the impacts it is likely to have on their learning:**


Back in January, I, like many others, thought we could design our
coursework to outwit students who would rely on AI to complete
their assignments. I thought we could create personalized
discussion questions, meaningful and engaged essay assignments,
and quizzes that were sufficiently individualized to course
materials that they would be AI-proof. Turns out, I was incorrect.
Particularly with the arrival of GPT-4, there is very little I can
assign to my undergraduates that the computer can’t at least take
a stab at. Students may have to fill in a few details and remember
to delete or add some phrases, but they can avoid most of the
thinking—and save a lot of time.


One of her proposed solutions, at least in the short term, is to have
students revise work that an AI checker like [ZeroGPT determines to be](https://www.zerogpt.com/)
more than 50 percent AI-generated.



_**In reality, it’s very easy**_
_**to use AI to do the lion’s share**_



_**of the thinking while still**_
_**submitting work that looks like**_



_**your own. Once that becomes**_



_**clear, it follows that massive**_



_**structural change will be**_
_**needed if our colleges are going**_



_**to keep training students to**_



_**think critically.**_



_The Chronicle of Higher Education,_



_[Owen Kichizo Terry, May 2023](https://www.chronicle.com/article/im-a-student-you-have-no-idea-how-much-were-using-chatgpt)_



HIGHER EDUCATION **6**


### **COMPETENCY-BASED EDUCATION AND GENERATIVE AI**



**GENERATIVE AI AND COMPETENCY-**

**BASED EDUCATION**


**[Data scientist J. Rogel-Salazar’s February 2023 discussion of generative](https://medium.com/@quantum_tunnel/the-rise-of-generative-ai-usage-in-competency-based-education-5789f38b6ffc)**
**AI in competency-based education suggests that a collaborative**
**approach to AI could allow the tool to function as a coach for students**
**and a formative assessment tool for faculty.** He defines “competencybased education” as “a student-centred approach that focuses on
mastering skills and knowledge rather than accumulating credit hours”
and [which](https://www.teachthought.com/learning/what-is-competency-based-learning/) “focusses on the student’s demonstration of desired learning
outcomes as central to the learning process.” Rogel-Salazar’s primary
example of such a tool and how it might work is quoted below. It derives
from a November 2022 [article in](https://dl.acm.org/doi/10.1145/3555603) _Proceedings of the ACM on Human-_
_Computer Interaction_ .


USE-CASE SPOTLIGHT – CONVOWIZARD


_Consider for instance the tool recently unveiled by researchers at Cornell_
_University called ConvoWizard. The tool can detect when online debates are_
_becoming heated and could lead to an irredeemable meltdown._ _**ConvoWizard**_

_**is a browser extension that uses a neural network trained on data pulled**_
_**from the Change My View subreddit to warn users when their comments are**_

_**likely to escalate tension.**_ _[You can read more about this in the paper here. In](https://dl.acm.org/doi/10.1145/3555603)_
_tests, more than half of participants reported that the warnings stopped them_

_from posting a comment they would have regretted, while 68% felt the tool’s_

_estimates of risk were as good as or better than their own intuition._


_In other words, the tool lets users know when the conversation is getting tense_

_as they write their replies and provides warnings as to whether their comment_
_will escalate tension_ _**. One could argue that AI tools such as ConvoWizard can**_

_**help support competency-based learning by enabling high-quality online**_
_**discussions: students can receive real-time feedback that helps them develop**_

_**communication skills that are critical for success in many careers.**_



**WHY COACHING IS ESSENTIAL TO**

**COMPETENCY-BASED EDUCATION**


**Neither Salazar’s proposal to use generative AI as a coaching and**
**assessment tool nor the competency-based learning framework he**
**attaches it too differ substantively from established best practices in**
**postsecondary teaching.** Teaching professional development service
TeachThought, which [provided the definition of Competency-Based](https://www.teachthought.com/learning/what-is-competency-based-learning/)
Learning cited by Rogel-Salazar, compares it with traditional learning
models which they say rely on summative assessment. The two
definitions are provided below, and the key difference between the
models is the purported “flexibility” of CBE, which enables students to
progress at their own pace through content after achieving mastery.
However, “its effectiveness…depends on the ecology it is embedded in,”
and CBE requires “diverse support systems, robust assessment forms, and
clear and manageable learning outcomes,” placing the burden of ongoing
assessment on faculty. Again, a focus on learning as a process is central.


DEFINING COMPETENCY-BASED EDUCATION

_Definitions quoted from TeachThought,_ _[2016.](https://www.teachthought.com/learning/what-is-competency-based-learning/)_



**Competency-Based Learning**


“In a competency-based learning system,
students are not allowed to continue until

they have demonstrated mastery of the
identified competencies (i.e., the desired
learning outcomes to be demonstrated). In

this way, the definition of competencybased learning is closely tied to mastery

learning.”


“Its strengths lie in its flexibility, as
learners are able to move at their own
pace. This supports students with diverse

knowledge backgrounds, literacy levels,

and other related aptitudes.”



**Traditional Education**


“In other learning models, students are

exposed to content–whether skills or

concepts–over time, and success is

measured summatively.”



HIGHER EDUCATION **7**


### **O PEN AI BEST PRACTICES FOR FORMATIVE ASSESSMENT**



**O** **PEN** **AI ON GENERATIVE AI AS A**

**PEDAGOGICAL TOOL – CURRENT STATUS**


**OpenAI’s own Educator FAQ** **[resource contends that AI detector](https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own)**
**resources generally are not reliable enough to justify “judgments about**
**students with potentially lasting consequences,” and recommends**
**alternative, instructor-sanctioned uses of AI that highlight the**
**development of students’ critical thinking faculties.** They provide three
examples of how ChatGPT can help instructors develop students’
capabilities in ways that could be assessed (reproduced in the figure to
[the right). The expert consensus on AI detection tool like GPTZero is that](https://arstechnica.com/information-technology/2023/09/openai-admits-that-ai-writing-detectors-dont-work/)
they do not work, and even OpenAI’s experimental AI Classifier achieved
only a 26 percent accuracy rate, which is worse than a random guess.


**At present, OpenAI’s recommendations place the burden on students to**
**be honest about their use of generative AI and faculty to analyze the**
**ways in which students interact with AI-generated text to demonstrate**
**critical thinking skills.** Student interactions can be saved via Shared Links
[and then evaluated. John Warner’s essay on pedagogical uses of ChatGPT](https://www.insidehighered.com/blogs/just-visiting/resisting-ai-hype-cycle-education)
warns against the temptation of using AI to “substitute for human
response to student writing” even as he concedes that “there’s some
occasions where AI responses may be genuinely helpful to student
learning.” He agrees with the OpenAI best practices outlined to the right,
which stress the value of formative assessment of students’ processes as
the most essentially human part of writing assessment:


…because writing is an embodied process and writing is thinking,
the best feedback on student writing is not summative—which
LLMs will do passably—but formative, where the instructor can
help the student reconsider and reflect upon some part of their
process. Asking a writing teacher to do this where they have not
read the student work is like asking a coach to work with a team
where they know the score but have not watched the game itself.



THREE GOALS FOR EFFECTIVE AI USE IN THE

CLASSROOM, WITH RELATED STRATEGIES
_Figure reproduces content from_ _[OpenAI. The content shown in orange italic font is](https://help.openai.com/en/articles/8313351-how-can-educators-respond-to-students-presenting-ai-generated-content-as-their-own)_
_particularly relevant to questions of assessment._
**1. Showing** **Educators can analyze student interactions with ChatGPT** _to observe critical thinking and problem-solving_
**their Work** _approaches._
**and Formative** **Shared links can enable students to review each other's**
**Assessment** **work,** fostering a collaborative environment. _[[Shared links](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq)_



**Educators can analyze student interactions with**
**ChatGPT** _to observe critical thinking and problem-solving_
_approaches._



**Shared links can enable students to review each other's**
**work,** fostering a collaborative environment. _[[Shared links](https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq)_
_are a new feature that allow users to generate a unique URL_
_for a ChatGPT conversation, which can then be shared with_
_friends, colleagues, and collaborators. Shared links offer a_
_new way for users to share their ChatGPT conversations,_
_replacing the old and burdensome method of sharing_
_screenshots.]_



**2. Information**
**and AI**
**Literacy**


**3. Creating**
**Accountability**



**By keeping a record of their conversations with AI,**
**students can reflect on their progress over time.** They
can see how their skills in asking questions, analyzing
responses, and integrating information have developed.
_Teachers can also use these records to provide personalized_
_feedback and support individual growth._


**Students can demonstrate their ability to interact with AI**
**and their understanding of the shortcomings of AI**
**systems** _**.**_ _Educators can assess the quality of the questions_
_asked, the relevance of the information obtained, and how_
_well the student understood to challenge, double-check, and_
_consider potential biases in that information._


**We anticipate a future where the use of AI tools like**
**ChatGPT is commonplace.** _Encouraging responsible use_
_helps students prepare for a future where they may be_
_expected to leverage AI in different contexts._


**Sharing interactions with the model ensures that**
**students are held accountable for the way they use AI in**
**their work.** _Educators can verify that students are engaging_
_with the tool responsibly and meaningfully, rather than_
_simply copying answers._



HIGHER EDUCATION **8**


### **OPTIMAL GENERATIVE AI AND FACULTY ROLES IN INSTRUCTION**



**GENERATIVE AI AS A TUTORING SERVICE**


**As demonstrated by nascent products like Khanmigo and Duolingo’s**
**RolePlay (discussed in more detail on subsequent pages), one of the most**
**promising applications of generative AI is as a tutor to struggling**
**students.** MIT Horizon’s December 2023 [blog post,](https://horizon.mit.edu/insights/can-generative-ai-unlock-technology-enabled-tutoring-for-everyone) _Can Generative AI_
_Unlock Technology-Enabled Tutoring, for Everyone?_ Notes that a 2020
National Bureau of Economic Research [metastudy found tutoring to be](https://www.nber.org/system/files/working_papers/w27476/w27476.pdf)
“among the most flexible and potentially transformative learning program
types available at the PreK-12 levels” (57). The report, which focuses on
the use of human tutors, notes that:


With effect sizes averaging at over a third of a standard deviation
and impacts consistently significant across a wide range of
program and study characteristics, our review’s meta-analytic
findings demonstrate not only the power of tutoring, but its
versatility. As customized learning grows in prominence across
today’s educational systems, there is little doubt that tutoring
programs will constitute a key workhorse policy model. (57-58)


**The MIT authors** **[suggest that research links two elements of tutoring](https://horizon.mit.edu/insights/can-generative-ai-unlock-technology-enabled-tutoring-for-everyone)**
**programs to student success, and then asks whether either are “things**
**generative AI can do well.”** The drivers of success they identify are:


➢ Social connection and motivational support
➢ Cognitive scaffolding that unlocks a student’s own thinking


While they acknowledge that ChatGPT and similar resources can “adopt
particular tones and strategies that build up rapport” they contend that “it
is not as appropriate for the longer-term social connection that comes
from having a caring mentor who is invested in your success and who
checks in with you.” In terms of cognitive scaffolding, ChatGPT tools like
Khanmigo are getting better at helping users think through how to come
up with a correct answer or conclusion, rather than simply producing it.



**CONTINUED RELEVANCE OF HUMAN**

**INSTRUCTORS**


**Multiple sources recognize both the emerging promise of generative AI**
**as an always-on tutoring and formative assessment tool, but suggest that**
**the social connections found in teaching and learning relationships are**
**essential for motivating many students.** Two iterations of this idea are
quoted below, and both of them note the continuing need for human
oversight of the teaching and learning process, as well as the role of AI in
providing targeted feedback and practice for students.


**The idea of AI tutoring is compelling enough that the Defense Advanced**
**Research Projects Agency (DARPA) is** **[soliciting proposals “to create](https://www.darpa.mil/news-events/2022-11-03)**
**customized learning experiences that improve training of new skills in**
**adults who have completed postsecondary education.”** Their focus is on
“complex subjects required for national security, such as AI engineering.”


AI TUTORS AND HUMAN TEACHERS

_[Figure reproduces content from MIT Horizon and](https://horizon.mit.edu/insights/can-generative-ai-unlock-technology-enabled-tutoring-for-everyone)_ _[Eric Hudson.](https://erichudson.substack.com/p/back-to-school-with-ai-part-3-competency)_








|MIT Horizon|Col2|
|---|---|
|“…having social connections that help you,<br>both by keeping you accountable and by<br>rooting for you over the longer term, are<br>critical.**Perhaps a productive model for**<br>**the future involves a human ‘meta-tutor’**<br>**that helps guide a student’s interactions**<br>**with their personal robot tutor, with the**<br>**human helping build your personalized**<br>**path and stopping to help you engage**<br>**with a generative AI tutor when you get**<br>**stuck.”**|“…having social connections that help you,<br>both by keeping you accountable and by<br>rooting for you over the longer term, are<br>critical.**Perhaps a productive model for**<br>**the future involves a human ‘meta-tutor’**<br>**that helps guide a student’s interactions**<br>**with their personal robot tutor, with the**<br>**human helping build your personalized**<br>**path and stopping to help you engage**<br>**with a generative AI tutor when you get**<br>**stuck.”**|



HIGHER EDUCATION **9**


### **O PEN AI CURRENT ASSESSMENT PRODUCTS**



**C** **HAT** **GPT USE CASES OUTSIDE OF HIGHER**

**EDUCATION**


**According to OpenAI, partner organizations outside of higher education**
**are building “AI powered education tools” with the potential to provide**
**opportunities for practice as well as formative and summative**
**assessments.** The examples below derive from OpenAI’s website.


O PEN AI OVERVIEW OF C HAT GPT-POWERED

PEDAGOGICAL TOOLS

_[Figure reproduces content from OpenAI.](https://help.openai.com/en/articles/8313434-are-there-any-resources-for-educators-to-learn-more-about-ai)_











**EARLY RESPONSES TO THE C** **HAT** **GPT-**

**BASED TOOLS**


**In an October 2023** _**Forbes**_ **[feature, Charles Towers-Clark evaluated the](https://www.forbes.com/sites/charlestowersclark/2023/10/23/khan-academy-an-ai-revolution-in-education-or-threat-to-human-skills/?sh=521c13c42cf3)**
**promise and shortcomings of Khanmigo, finding that it “only acts as a**
**teaching assistant.”** Whether the tool is as interactive as promised
remains to be seen, and Towers-Clark’s experience suggests that the line
between coaching students through a task and doing it for them was
often blurry:


It aids in grading papers, refreshing teachers' knowledge, and
crafting lesson plans. Moreover, it provides personalized guidance
to students, offering assessments for teachers to follow up on.
When it comes to its intended functionality, Khanmigo appears to
deliver and my experience was positive. It encouraged me to
write, offering suggestions on how to restructure my content and
incorporate additional relevant points. **However, it didn't strictly**
**adhere to the Socratic method; I could prompt it to rewrite text**
**on a paragraph-by-paragraph basis when I posed the right**
**prompt.**


**Nadia Bidarian’s August 2023** **[profile of Khanmigo published by CNN](https://www.cnn.com/2023/08/21/tech/khan-academy-ai-tutor/index.html)**
**suggests that its propensity to hallucinate, or generate incorrect or**
**made-up answers, remains a central problem.** This tendency appears
when Khanmigo serves as an interactive writing or research coach and as
a mathematics coach, where it can provide incorrect answers.


**The new edX platform,** **[called Xpert, is described as “a generative AI-](https://www.prnewswire.com/news-releases/2u-reports-results-for-second-quarter-2023-301896138.html)**
**powered learning assistant” and paired with an edX ChatGPT plugin**
**“which enables ChatGPT Plus users to seamlessly discover higher**
**education programs across edX's library of courses.”** Details about this
platform and its impacts remain limited, but the platform is meant to
[provide customized academic assistance, course discovery services,](https://press.edx.org/edx-debuts-two-ai-powered-learning-assistants-built-on-chatgpt)
customer service, and course content summaries.



HIGHER EDUCATION **10**


# GENERATIVE AI CASE STUDIES AND ASSESSMENT USE CASES

_Examples of how universities globally and in the United States, as well as other_
_educational entities, are using generative AI in assessment._


### **CASE STUDY – DUOLINGO ROLEPLAY AND EXPLAIN MY ANSWER**



**CURRENT DUOLINGO DEPLOYMENT OF AI**


**Language learning app Duolingo introduced two ChatGPT-powered tools**
**in spring 2023 as part of their $14 per month Max subscription.** As of
[August 2023 the two AI tools are the flagship features of its top-tier](https://duoplanet.com/duolingo-max-review/)
subscription level. They include RolePlay, which “gives users the
opportunity to take everything they learn in their ordinary lessons and
use it in a conversation with one of Duolingo’s characters,” and Explain
My Answer, which “goes into detail on the answers you provide in your
lessons, highlighting what you got right, where you’ve gone wrong, and
where you can improve.”


**The ChatGPT-4-based RolePlay** **[uses AI to converse with users in a](https://www.forbes.com/sites/bernardmarr/2023/04/28/the-amazing-ways-duolingo-is-using-ai-and-gpt-4/?sh=31edacb61346)**
**simulated encounter (the main example given in reviews of the tool is**
**ordering a drink in a café) and to “ensure the conversation is, broadly**
**speaking, remaining focused on relevant topics” rather than veering off**
**into irrelevant directions.** Carina Chocano’s April 2023 _New Yorker_ [article](https://www.newyorker.com/magazine/2023/04/24/how-much-can-duolingo-teach-us)
on Duolingo’s use of AI describes it as follows:


…as GPT-4 and the human user generate dialogue in RolePlay, a
separate machine-learning model monitors the results, and
registers whether they are within the projected range of
appropriate conversation. ‘If it’s out of scope,’ [Duolingo head of
artificial intelligence Klinton Bicknell] said, ‘then we just tell the
learner, ‘Hey, I think you’re straying a little off topic.’”


**Future deployments of AI at Duolingo will focus on generating course**
**content and exercises according to an April 2023** _**Forbes**_ **[article:](https://www.forbes.com/sites/bernardmarr/2023/04/28/the-amazing-ways-duolingo-is-using-ai-and-gpt-4/?sh=31edacb61346)**


Generating new course content has traditionally been a
bottleneck – and this is one job in particular that the present-day
generation of language models has proven to be highly efficient

at.



_make no mistake – it’s not a_
_replacement for human interaction._ _**As**_

_**flexible as it already is, it can still feel**_
_**a little cold and predictable, especially**_

_**after repeating a scenario a couple of**_

_**times.**_ _Even if you offer a really_
_fleshed-out answer, the character can_

_still respond as if following a script. It_

_could do with loosening up a bit.”_



**DUOLINGO REVIEWS AND CRITIQUES**



_there’s currently no way of_
_selecting which part._ _**Although it takes**_

_**on a chatbot format, you can’t**_

_**actually ask any of your own**_
_**questions.**_ _Instead, you’re limited to a_

_set of three responses: yes, no, and_

_show me an example.”_



_**Right now, I don’t**_
_**think Max has enough to**_

_**justify the current price**_
_**point. Most users will be**_
_**better off either upgrading**_

_**to Super, or sticking with**_
_**the free plan and spending**_
_**their money elsewhere. Max**_

_**isn’t going replace human**_
_**tutors any time soon, and,**_

_**by itself, certainly isn’t**_

_**going to make you**_

_**fluent.**_


_Duoplanet review of Duolingo Max_

_AI-powered features,_

_[August 2023](https://duoplanet.com/duolingo-max-review/)_



**Duoplanet’s** **[review of RolePlay and](https://duoplanet.com/duolingo-max-review/)**
**Explain My Answer suggests that the**
**new AI features are helpful for those**
**seeking to learn French or Spanish (the**
**two languages for which they are**
**available) and that they surpass “the**
**standard Duolingo experience” which**
**“can sometimes leave you wanting**
**something a little less gamey, and a little**
**more authentic.”** In terms of value for
the subscription cost, the reviewer
remains unconvinced that the ChatGPTpowered features are worth the higher
subscription cost to access them.
Critiques of these tools suggest that
while they are promising, they remain
fairly limited in terms of interactivity.



CRITIQUES OF DUOLINGO AI TOOLS
_[Quotations derive from Duoplanet, August 2023.](https://duoplanet.com/duolingo-max-review/)_

_“RolePlay is great. I’m sure it’s going to_
_be a massive help for a lot of users. But_



_“Explain My Answer, although being a_



_welcome addition, only seems to_
_explain one part of the answer — and_



HIGHER EDUCATION **12**


### **CASE STUDY – UNIVERSITY OF WISCONSIN GUIDING PRINCIPLES**



**CORE GOAL IS PREPARING STUDENTS FOR**

**A WORLD WHERE AI IS UBIQUITOUS**


**Like most institutions, University of Wisconsin** **[recognizes the need to](https://teachlearn.wisc.edu/generative-ai/)**
**prepare students to function in a world where generative AI tools are**
**readily available.** The university also assumes that “skills such as prompt
engineering, problem-solving, bias detection and intellectual curiosity” will
be essential, given the limitations and occasional unreliability of
generative AI models. They distill the university’s goals with respect to AI
down to efforts to help students:


➢ Gain literacy in AI tools and learn to use them fluently, creatively and

ethically
➢ Develop core competencies in conjunction with AI competencies (e.g.

critical thinking, creativity, communication, citizenship, cultural
sensitivity, ethics, etc.)
➢ Build capacity to live and work in tandem with evolving versions of AI


**As shown in the figure to the right, AI introduces a range of concerns**
**from academic dishonesty to bias to data privacy and theft of intellectual**
**property.** Especially important considerations are shown in boldface
orange italic font and include the need to have explicit, recurring
conversations about appropriate use of AI within the course and to
scaffold writing assignments with ample instructor support to avoid
situations where students are more likely to turn to generative AI as a
shortcut in the face of academic challenges. Notably, the policy forbids
faculty from outsourcing grading, assessment, and feedback to AI but
permits its use in shaping feedback for students.


**Laura Schmidli, et al., of University of Wisconsin published a** **[guide to](https://idc.ls.wisc.edu/ls-design-for-learning-series/using-artificial-intelligence-in-the-classroom/)**
**using AI in the classroom in early 2023 that includes specific activities**
**designed to help students interface with AI and learn about its strengths**
**and limitations within the context of their discipline.** These exercises,
which are unusually robust and specific, are reproduced on the next page.


HIGHER EDUCATION



**GUIDING PRINCIPLES FOR INSTRUCTORS**

_Figure summarizes content from the University of Wisconsin generative AI guidelines,_
_[2023.](https://teachlearn.wisc.edu/generative-ai/)_


_s_ _**Advance Accessibility and Equity**_ _– Opportunities include AI_
_assistance for students struggling with writing and entering a new_
_discipline. Challenges include AI’s potential to “generate racist, sexist,_
_and other kinds of biased responses and potentially promote such_
_biases,”_ _**accessibility barriers for students with disabilities, and unfair**_
_**advantages for students who can afford access to premium**_
_**generative AI tools.**_


_**Protect Data and Intellectual Property**_ _– Unless required by the_
_assignment, students should not have to submit drafts of assignments_
_created with AI or input personal information or course documents_
_like prompts into AI tools._ _**Instructors should not input student work**_
_**into AI tools to automate feedback and comments.**_


_**Consider Educational Uses**_ _– “Students can_ _**dialogue with AI chat-**_
_**bots in ways that generate new knowledge and insights**_ _and that_
_mimic conversations with peers or even instructors” and instructors_
_can use AI to help design course materials, assignments, and_
_accessible lessons, and to_ _**inform their feedback on student work.**_


_**Consider Adapting Learning Experiences and Assessments**_ _–_
_**Scaffolding assignments to reduce students’ temptation to use AI,**_
_using non-written assessments, focusing on metacognitive strategies_
_like reflections, introducing group projects, and focusing on writing_
_processes are essential recommendations._


_**Discuss Course Expectations and Academic Integrity with Students**_ _–_
_**Communicate the expectations for AI usage early and often, with**_
_**clear examples**_ _of where it can and cannot be used. Avoid using a_
_‘misconduct’ approach to suspected uses of AI._


_**Address Potential Misconduct Using Established Policies and**_
_**Processes**_ _–_ _**Instructors should not rely on AI detectors, which have a**_
_**history of false positive results and bias against non-native English**_
_**speakers.**_ _When illicit AI usage is suspected, faculty should follow_
_standard university procedures for investigating academic_
_misconduct._


**13**


### **CASE STUDY – UNIVERSITY OF WISCONSIN AI-IMBUED ACTIVITIES**



**INTEGRATING AI INTO THE WRITING**

**PROCESS IN YOUR CLASSROOM**


_[2023.](https://idc.ls.wisc.edu/ls-design-for-learning-series/using-artificial-intelligence-in-the-classroom/)_ _[Figure reproduces content created by Schmidli, et al., University of Wisconsin, 2023.](https://idc.ls.wisc.edu/ls-design-for-learning-series/using-artificial-intelligence-in-the-classroom/)_

_Bolding, formatting, and emphases derive from Hanover._



**EXPLORING CAPABILITIES AND**

**LIMITATIONS OF AI IN YOUR CLASSROOM**

_[Figure reproduces content created by Schmidli, et al., University of Wisconsin, 2023.](https://idc.ls.wisc.edu/ls-design-for-learning-series/using-artificial-intelligence-in-the-classroom/)_
_Bolding, formatting, and emphases derive from Hanover._







_**AI Drafting Process: Students use AI to**_













_**Rubric Calibration with AI Writing: The**_
_**instructor uses AI to generate an essay, thesis,**_
_**or other written work. Groups then use a rubric**_

_**to evaluate the AI’s work,**_ _and suggest changes_

_or improvement to the rubric. This can help_
_students think about how they define high-_

_quality work, and how a rubric might help_

_identify AI-generated work._


_**AI Thesis Revision: Students use AI to quickly**_

_**generate thesis statements**_ _on a variety of_

_topics. Individually_ _**students revise these**_
_**statements**_ _and share two that are strongest to_

_a group for feedback, including what prompts_

_they provided the AI and what revisions they_

_made to each statement…_


_**AI Feedback: Students ask AI to evaluate an**_

_**initial draft of a short writing assignment,**_

_asking AI to focus on a specific element._

_Students then incorporate any valuable_
_feedback into their work, and share their_
_revisions with a small group. This can help_
_students get another perspective on writing_
_quickly, while encouraging them to consider_

_that feedback critically._



_**generate a draft of a simple writing**_
_**assignment. Students then analyze the AI’s**_
_**writing,**_ _focusing on accuracy, bias, or other_
_characteristics important in your course. You_
_may also ask students to improve the AI’s draft_

_to complete a second draft._


_**Planning and Evaluating AI Use: Students**_
_**create a plan for using AI within a specific**_
_**assignment,**_ _like a scaffolded research paper,_

_where they articulate for which steps it is_
_valuable and appropriate to use AI, and when_
_original thought and creativity are needed and_

_why. This activity works best when sequenced_
_with other activities that explore AI capabilities._


_**Citing AI: If students are using AI in your class**_

_**assignments, discuss if and how AI should be**_

_**cited.**_ _For example, students may cite it as a_
_source or disclose their use of it in a disclaimer,_

_footnote, or appendix that includes the_

_prompts they created…_















_**Writing with Images:**_ _Students or instructors_
_**use image-generating AI as part of a reflective**_
_**writing, freewriting, or creative writing process**_
_**in any language**_ _. Students can use AI to quickly_

_visualize descriptions from their writing, or_
_students or instructors can use AI to generate_

_images that prompt elaboration in writing._



HIGHER EDUCATION **14**


### **CASE STUDY – MONTCLAIR STATE UNIVERSITY AI STRATEGIES**



**BEST PRACTICES BY STRATEGY TYPE**



AI WRITING DETECTION RED FLAGS

_Figure reproduces_ _[guidelines from the Montclair State University Office for Faculty](https://www.montclair.edu/faculty-excellence/teaching-resources/clear-course-design/practical-responses-to-chat-gpt/red-flags-detecting-ai-writing/)_
_Excellence, which cautions that “no software is able to detect AI-generated content_
_with 100% certainty” but provides the following signs of AI-inflected writing._



_**Teaching and learning**_
_**in the era of generative AI does**_
_**not need to be all about damage**_



_**control. Plagiarism and ethics**_

_**concerns are real, but on the**_

_**other hand, the advance of**_
_**generative AI gives us a special**_

_**opportunity to focus on the**_
_**challenges of teaching and work**_

_**out strong solutions.**_


_**Generative AI itself can be a**_
_**learning tool – as anyone who**_

_**gets into the tool and starts**_
_**inputting queries and studying**_

_**the output knows. Your**_
_**synapses are firing as you write**_

_**and read the rapidly generated**_

_**text. It’s fun, and you’re likely**_

_**wide awake, judging,**_
_**speculating, disagreeing,**_
_**agreeing, and doing all those**_

_**things that happen when an**_
_**engaged reader encounters text.**_

_**These potentials can be used in**_

_**the classroom.**_


_Montclair State University_
_Office for Faculty Excellence,_
_[“Practical Responses to Generative](https://www.montclair.edu/faculty-excellence/teaching-resources/clear-course-design/practical-responses-to-chat-gpt/)_

_[AI”](https://www.montclair.edu/faculty-excellence/teaching-resources/clear-course-design/practical-responses-to-chat-gpt/)_


HIGHER EDUCATION



**Montclair State University’s** **[strategies](https://www.montclair.edu/faculty-excellence/teaching-resources/clear-course-design/practical-responses-to-chat-gpt/teaching-with-chatgpt-assignment-design-tips-ideas/)**
**for teaching in a post-Chat GPT world**
**are divided into three basic categories:**
**assigning tasks that AI cannot yet do**
**convincingly, emphasizing the process**
**of completing assignment over the**
**product, and having students engage**
**with and reflect on their use of**
**ChatGPT.** Examples of recommended
assignments that can confound
generative AI include the use of diverse
media (e.g., having students produce
videos), assignments that require
students to connect the topic with
personal experience, assignments that
reference texts unavailable to
generative AI, and handwritten
assignments.



**15**







**Process-focused approaches include**
**group projects, flipped classrooms**
**with an emphasis on in-class work, and**
**scaffolded assignments with multiple**
**components** **due** **as** **the** **project**
**develops.** Ideas that require students
to interact with generative AI include
“critical evaluation of AI outputs” and
blind evaluations to determine whether
AI or a human created a piece of
writing, with attention to the features
that distinguish AI-produced content.








### **CASE STUDY – MONASH UNIVERSITY ASSESSMENT STRATEGIES**



**OVERVIEW**



**Monash University’s** **[guide to Generative AI and Assessment urges faculty to “target higher order thinking” when designing](https://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence/generative-ai-and-assessment)**
**assessments, while conceding that limitations on instructor time could make implementing more AI-resistant assignments**
**difficult.** The university argues that “it may now be necessary to target forms of knowledge and expression that are more difficult
for generative AI technologies - critical thinking, evaluation or creativity, for example.”



ASSESSMENT ACTIVITIES BY LEVEL OF DIFFICULTY FOR C HAT GPT TO REPLICATE

_[The three easier activities for generative AI are shown on the left, with more difficult, AI-resistant activities on the right. Table reproduces content from Monash University.](https://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence/generative-ai-and-assessment)_































HIGHER EDUCATION _e intern.”._ **16**


